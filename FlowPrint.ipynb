{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from flowprint.flowprint import FlowPrint\n",
    "from flowprint.preprocessor import Preprocessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os.path as p\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Note:\n",
    "# The model requires WireShark to be installed for it to work properly.\n",
    "# WireShark is a network protocol analyzer that the model depends on for handling or pcap files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    This function loads pcap file paths and their corresponding labels from a specified directory.\n",
    "    \n",
    "    Assumptions:\n",
    "    - The dataset directory structure must consist of a main folder (specified by 'path')\n",
    "      containing subfolders named after the applications. Each subfolder should contain \n",
    "      pcap files related to that specific application.\n",
    "    \n",
    "    Parameters:\n",
    "    - path (str): The path to the main directory containing subdirectories with pcap files.\n",
    "    \n",
    "    Process:\n",
    "    - The function iterates over all files in the specified directory (excluding hidden files).\n",
    "    - For each valid file found:\n",
    "        1. The full file path is appended to the global list 'AllPcaps'.\n",
    "        2. The file name (without the extension) is extracted and appended to the global list 'AllLabels'.\n",
    "           This name typically corresponds to the application's name.\n",
    "    \n",
    "    Note:\n",
    "    - The lists 'AllPcaps' and 'AllLabels' are expected to be defined globally before calling this function.\n",
    "    \n",
    "    Example:\n",
    "    If the directory structure is:\n",
    "    /path/to/main_folder/\n",
    "        ├── AppA/\n",
    "        │   ├── capture1.pcap\n",
    "        │   └── capture2.pcap\n",
    "        ├── AppB/\n",
    "            ├── capture1.pcap\n",
    "            └── capture2.pcap\n",
    "    Then after calling `load_data('/path/to/main_folder/')`, 'AllPcaps' will contain the paths to each pcap file,\n",
    "    and 'AllLabels' will contain 'capture1', 'capture2', etc., as labels.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(path):\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        AllPcaps.append(p.join(path, file))\n",
    "        AllLabels.append(p.splitext(file)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset_path'\n",
    "AllPcaps = []\n",
    "AllLabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "load_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Preprocessor object\n",
    "preprocessor = Preprocessor(verbose=True)\n",
    "\n",
    "# Create Flows and labels\n",
    "X, y = preprocessor.process(files =AllPcaps,\n",
    "                            labels=AllLabels,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time\n",
    "time = datetime.now().strftime('%H:%M:%S')\n",
    "filename = './flows_'+ time +'.p'\n",
    "# Save flows and labels to file 'flows.p'\n",
    "preprocessor.save(filename, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flows from file 'flows.p'\n",
    "# flow_path = 'name_of_file'\n",
    "# X, y = preprocessor.load(flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprint generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FlowPrint object\n",
    "flowprint = FlowPrint(\n",
    "    batch       = 300,\n",
    "    window      = 30,\n",
    "    correlation = 0.1,\n",
    "    similarity  = 0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit FlowPrint with flows and labels\n",
    "flowprint.fit(X_train, y_train)\n",
    "\n",
    "# Create fingerprints for test data\n",
    "fp_test = flowprint.fingerprint(X_test)\n",
    "# Predict best matching fingerprints for each test fingerprint\n",
    "y_pred = flowprint.predict(fp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fingerprints from file 'fingerprints.json'\n",
    "# This returns both the fingerprints and stores them in the flowprint object\n",
    "# fingerprints = flowprint.load('./tests/fingerprints_20:01:40.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FlowPrint object\n",
    "flowprint = FlowPrint(\n",
    "    batch       = 300,\n",
    "    window      = 30,\n",
    "    correlation = 0.1,\n",
    "    similarity  = 0.9\n",
    ")\n",
    "\n",
    "# Fit FlowPrint with flows and labels\n",
    "flowprint.fit(X_train, y_train)\n",
    "\n",
    "# Recognise which app produced each flow\n",
    "y_recognize = flowprint.recognize(fp_test)\n",
    "# Detect previously unseen apps\n",
    "# +1 if a flow belongs to a known app, -1 if a flow belongs to an unknown app\n",
    "y_detect    = flowprint.detect(fp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print report with 4 digit precision\n",
    "print(classification_report(y_test, y_recognize, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
